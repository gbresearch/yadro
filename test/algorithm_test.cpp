//-----------------------------------------------------------------------------
//  Copyright (C) 2011-2024, Gene Bushuyev
//  
//  Boost Software License - Version 1.0 - August 17th, 2003
//
//  Permission is hereby granted, free of charge, to any person or organization
//  obtaining a copy of the software and accompanying documentation covered by
//  this license (the "Software") to use, reproduce, display, distribute,
//  execute, and transmit the Software, and to prepare derivative works of the
//  Software, and to permit third-parties to whom the Software is furnished to
//  do so, all subject to the following:
//
//  The copyright notices in the Software and this entire statement, including
//  the above license grant, this restriction and the following disclaimer,
//  must be included in all copies of the Software, in whole or in part, and
//  all derivative works of the Software, unless such copies or derivative
//  works are solely in the form of machine-executable object code generated by
//  a source language processor.
//
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//  FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
//  SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
//  FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
//  ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
//  DEALINGS IN THE SOFTWARE.
//-----------------------------------------------------------------------------

#include "../util/gbtest.h"
#include "../util/misc.h"
#include "../archive/archive.h"
#include "../algorithm/gbalgorithm.h"
#include <iostream>
#include <thread>

namespace
{
    using namespace gb::yadro::algorithm;
    using namespace gb::yadro::util;
    using namespace gb::yadro::archive;

    //--------------------------------------------------------------------------------------------
    // test optimization with tuples of fundamental types
    GB_TEST(algorithm, genetic_optimization_test, std::launch::async)
    {
        using namespace std::chrono_literals;

        genetic_optimization_t optimizer([](auto x, auto y, auto z, auto v)
            { return x * x + y * y + std::exp(z) / 2 + std::exp(-z) / 2 - 1 + (v + std::sin(v)) * (v + std::sin(v)); },
            std::less<>{},
            std::tuple(0u, 10u), std::tuple(-10LL, 10LL), std::tuple(-10.f, 10.f), std::tuple(-10., 10.));

        auto [stat, opt_map] = optimizer.optimize(100ms, 5);

        // only testing in optimized build, debug build can be too slow and tests would fail randomly
#if defined(NDEBUG)
        gbassert(opt_map.size() == 5);
        gbassert(opt_map.begin()->first < 0.01); // may fail on very slow machines
#endif

#if defined(GB_DEBUGGING)
        std::cout << "\n" << stat << "\n";
        for (auto&& opt : opt_map)
        {
            auto&& [target, xyzv] = opt;
            auto [x, y, z, v] = xyzv;
            std::cout << "target: " << target << ", " << x << ", " << y << ", " << z << ", " << v << "\n";
        }
#endif
    }

    //--------------------------------------------------------------------------------------------
    // test optimization with tuples of fundamental types, providing acceptable_target
    GB_TEST(algorithm, genetic_optimization_test1, std::launch::async)
    {
        using namespace std::chrono_literals;

        genetic_optimization_t optimizer([](auto x, auto y, auto z, auto v)
            { return x * x + y * y + std::exp(z) / 2 + std::exp(-z) / 2 - 1 + (v + std::sin(v)) * (v + std::sin(v)); },
            std::less<>{},
            std::tuple(0u, 10u), std::tuple(-10LL, 10LL), std::tuple(-10.f, 10.f), std::tuple(-10., 10.));

        auto [stat, opt_map] = optimizer.optimize(0.01, 100ms, 5);

        // only testing in optimized build, debug build can be too slow and tests would fail randomly
#if defined(NDEBUG)
        gbassert(opt_map.size() == 5);
        gbassert(opt_map.begin()->first < 0.01); // may fail on very slow machines
#endif

#if defined(GB_DEBUGGING)
        std::cout << "\n" << stat << "\n";
        for (auto&& opt : opt_map)
        {
            auto&& [target, xyzv] = opt;
            auto [x, y, z, v] = xyzv;
            std::cout << "target: " << target << ", " << x << ", " << y << ", " << z << ", " << v << "\n";
        }
#endif
    }

    //--------------------------------------------------------------------------------------------
    // test optimization with tuples of ranges
    GB_TEST(algorithm, genetic_opt_range_test, std::launch::async)
    {
        using namespace std::chrono_literals;

        genetic_optimization_t optimizer([](auto&& r)
            { return r[0] * r[0] + r[1] * r[1] + std::exp(r[2]) / 2 + std::exp(-r[2]) / 2 - 1 + (r[3] + std::sin(r[3])) * (r[3] + std::sin(r[3])); },
            std::less<>{},
            std::tuple{ std::vector{0., -10., -10., -10.}, std::vector{10., 10., 10., 10.} });

        optimizer.set_opt_parameters(0.6, 0.5, 0.4);
        auto [stat, opt_map] = optimizer.optimize(100ms, 5);

        // only testing in optimized build, debug build can be too slow and tests would fail randomly
#if defined(NDEBUG)
        gbassert(opt_map.size() == 5);
        gbassert(opt_map.begin()->first < 0.01); // may fail on very slow machines
#endif

#if defined(GB_DEBUGGING)
        std::cout << "\n" << stat << "\n";
        for (auto&& opt : opt_map)
        {
            auto&& [target, xyzv] = opt;
            auto&& [v] = xyzv;
            std::cout << "target: " << target << ", " << v[0] << ", " << v[1] << ", " << v[2] << ", " << v[3] << "\n";
        }
#endif
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, genetic_optimization_mt_test, std::launch::async)
    {
        using namespace std::chrono_literals;

        genetic_optimization_t optimizer([](auto x, auto y, auto z, auto v)
            {
                auto sum{ 0. };
                for (auto i = 0; i < 1000; ++i)
                    sum += x * x + y * y + std::exp(z) / 2 + std::exp(-z) / 2 - 1 + (v + std::sin(v)) * (v + std::sin(v));
                return sum;
            },
            std::tuple(0u, 10u), std::tuple(-10LL, 10LL), std::tuple(-10.f, 10.f), std::tuple(-10., 10.));

        optimizer.add_solution(1, 0, 1e-2f, 1e-3);

        {// single thread
            //optimizer.optimize(10ms, 5);
            auto [stat, opt_map] = optimizer.optimize(200ms, 5);

#if defined(NDEBUG)
            gbassert(opt_map.size() == 5);
            gbassert(opt_map.begin()->first < 0.1); // may fail on very slow machines
#endif

#if defined(GB_DEBUGGING)
            std::cout << "single thread:\n" << stat << "\n";
            for (auto&& opt : opt_map)
            {
                auto [target, xyzv] = opt;
                auto [x, y, z, v] = xyzv;
                std::cout << "target: " << target << ", " << x << ", " << y << ", " << z << ", " << v << "\n";
            }
#endif
        }
        {// multithreaded
            optimizer.clear();
            gb::yadro::async::threadpool<> tp;
            auto [stat, opt_map] = optimizer.optimize(tp, 100ms, 5);
#if defined(NDEBUG)
            gbassert(opt_map.size() == 5);
            gbassert(opt_map.begin()->first < 1); // may fail on very slow machines
#endif

#if defined(GB_DEBUGGING)
            std::cout << "multithreaded:\n" << stat << "\n";
            for (auto&& opt : opt_map)
            {
                auto [target, xyzv] = opt;
                auto [x, y, z, v] = xyzv;
                std::cout << "target: " << target << ", " << x << ", " << y << ", " << z << ", " << v << "\n";
            }
#endif
        }
        {// multithreaded with acceptable_target
            optimizer.clear();
            gb::yadro::async::threadpool<> tp;
            auto [stat, opt_map] = optimizer.optimize(tp, 0.01, 100ms, 5);
#if defined(NDEBUG)
            gbassert(opt_map.size() == 5);
            gbassert(opt_map.begin()->first < 1); // may fail on very slow machines
#endif

#if defined(GB_DEBUGGING)
            std::cout << "multithreaded with acceptable_target:\n" << stat << "\n";
            for (auto&& opt : opt_map)
            {
                auto [target, xyzv] = opt;
                auto [x, y, z, v] = xyzv;
                std::cout << "target: " << target << ", " << x << ", " << y << ", " << z << ", " << v << "\n";
            }
#endif
        }
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, genetic_opt_serialization_test, std::launch::async)
    {
        using namespace std::chrono_literals;

        genetic_optimization_t optimizer([](auto x, auto y, auto z, auto v)
            { return x * x + y * y + std::exp(z) / 2 + std::exp(-z) / 2 - 1 + (v + std::sin(v)) * (v + std::sin(v)); },
            std::tuple(0u, 10u), std::tuple(-10LL, 10LL), std::tuple(-10.f, 10.f), std::tuple(-10., 10.));

        optimizer.optimize(10ms, 5);
        // serialize to memory archive
        gb::yadro::archive::omem_archive<> oma;
        oma(optimizer);
        optimizer.clear();
        // deserialize from memory archive
        gb::yadro::archive::imem_archive ima(std::move(oma));
        ima(optimizer);
        auto [stat, opt_map] = optimizer.optimize(1ms, 5);
#if defined(NDEBUG)
        gbassert(opt_map.size() == 5);
        gbassert(opt_map.begin()->first < 0.01); // may fail on very slow machines
#endif

#if defined(GB_DEBUGGING)
        std::cout << "\n" << stat << "\n";
        for (auto&& opt : opt_map)
        {
            auto [target, xyzv] = opt;
            auto [x, y, z, v] = xyzv;
            std::cout << "target: " << target << ", " << x << ", " << y << ", " << z << ", " << v << "\n";
        }
#endif
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, regression_test, std::launch::async)
    {
        using namespace std::chrono_literals;

        // test residuals
        auto data = std::vector<std::tuple<double, double>>{ {1., 0.}, { 2.,1. } };
        gbassert(residuals([](auto x) { return x; }, data) == std::vector{ 1., 1. });
        gbassert(residuals([](auto x) { return 1 + x; }, data, std::minus<>{}) == std::vector{ 0., 0. });

        {
            // least-squares optimization
            auto opt = least_squares_optimizer([](auto a, auto b) { return [=](auto x) { return a + b * x; }; },
                data, std::tuple{ -2., 2. }, std::tuple{ -3., 3. });

            auto [stat, opt_map] = opt.optimize(50ms, 4);

#if defined(GB_DEBUGGING)
            std::cout << stat << "\n";

            for (auto&& opt : opt_map)
            {
                auto [target, ab] = opt;
                std::cout << "target: " << target << ", " << tuple_to_string(ab) << "\n";
            }
#endif
            gbassert(opt_map.size() == 4);
            auto [target, a, b] = make_flat_tuple(*opt_map.begin());
            gbassert(almost_equal(target, 0., 0.01));
            gbassert(almost_equal(a, 1., 0.1));
            gbassert(almost_equal(b, 1., 0.1));
        }

        // least absolute value optimization
        {
            auto opt = least_abs_optimizer([](auto a, auto b) { return [=](auto x) { return a + b * x; }; },
                data, std::tuple{ -2., 2. }, std::tuple{ -3., 3. });

            auto [stat, opt_map] = opt.optimize(50ms, 4);

#if defined(GB_DEBUGGING)
            std::cout << stat << "\n";

            for (auto&& opt : opt_map)
            {
                auto [target, ab] = opt;
                std::cout << "target: " << target << ", " << tuple_to_string(ab) << "\n";
            }
#endif
            gbassert(opt_map.size() == 4);
            auto [target, a, b] = make_flat_tuple(*opt_map.begin());
            gbassert(almost_equal(target, 0., 0.1));
            gbassert(almost_equal(a, 1., 0.1));
            gbassert(almost_equal(b, 1., 0.1));
        }
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, kolmogorov_smirnov, std::launch::async)
    {
        std::mt19937 gen(12345);
        std::normal_distribution<> norm1(0.0, 1.0);
        std::uniform_real_distribution<double> uniform1(0.0, 1.0);
        std::normal_distribution<> norm2(0.0, 1.0);
        std::uniform_real_distribution<double> uniform2(0.0, 1.0);

        auto ks = [&](auto dist1, auto dist2, auto test_size)
            {
                std::vector<double> sample1(test_size);
                std::vector<double> sample2(test_size);
                for (int i = 0; i < test_size; ++i) {
                    sample1[i] = dist1(gen);
                    sample2[i] = dist2(gen);
                }
                auto [_, p_value] = kolmogorov_smirnov_test(sample1, sample2);
                return p_value;
            };

        gbassert(ks(norm1, norm2, 1000) > 0.05);
        gbassert(ks(uniform1, uniform2, 1000) > 0.05);
        gbassert(ks(norm1, uniform1, 1000) < 0.05);
        gbassert(ks(uniform1, norm1, 1000) < 0.05);
        gbassert(ks(norm2, uniform2, 1000) < 0.05);
        gbassert(ks(uniform2, norm2, 1000) < 0.05);
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, fft_decompose_test, std::launch::async)
    {
        std::vector<double> data(1024);
        std::generate(data.begin(), data.end(), [n = 0]() mutable { return std::sin(n++ * 0.1); });
        auto components = fft_decompose(data);
        gbassert(components.size() == 513);

        auto calc_error = [](auto&& data, auto&& components)
            {
                std::vector<double> reconstructed(data.size());
                for (const auto& [magnitude, frequency, phase] : components) {
                    for (size_t i = 0; i < data.size(); ++i) {
                        reconstructed[i] += magnitude * cos(2 * std::numbers::pi * frequency * i + phase);
                    }
                }
                double error = 0.0;
                for (size_t i = 0; i < data.size(); ++i) {
                    error += pow(data[i] - reconstructed[i], 2);
                }
                return sqrt(error / data.size());
            };

        gbassert(calc_error(data, components) < 0.001);
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, bluestein_test, std::launch::async)
    {
        // Use an arbitrary length (not a power of 2).
        size_t N = 1000;
        std::vector<double> test_data(N);

        // Fill test_data with 10 periods of a sine wave.
        for (size_t i = 0; i < N; ++i) {
            test_data[i] = sin(2 * std::numbers::pi * 10 * i / N);
        }

        // Compute the Bluestein FFT (returns sorted positive frequency components).
        auto sortedComponents = bluestein(test_data);
        gbassert(sortedComponents.size() == 501);

        auto [magnitude, frequency, phase] = sortedComponents[0];
        gbassert(almost_equal(magnitude, 1., 0.01));
        gbassert(almost_equal(frequency, 0.01, 0.001));
        gbassert(almost_equal(phase, -1.5708, 0.0001));

        auto calc_error = [](auto&& data, auto&& components)
            {
                std::vector<double> reconstructed(data.size());
                for (const auto& [magnitude, frequency, phase] : components) {
                    for (size_t i = 0; i < data.size(); ++i) {
                        reconstructed[i] += magnitude * cos(2 * std::numbers::pi * frequency * i + phase);
                    }
                }
                double error = 0.0;
                for (size_t i = 0; i < data.size(); ++i) {
                    error += pow(data[i] - reconstructed[i], 2);
                }
                return sqrt(error / data.size());
            };

        gbassert(calc_error(test_data, sortedComponents) < 1e-10);
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, shapiro_wilk_tst, std::launch::async)
    {
        std::vector<double> vec_data = { 12.9, 14.6, 15.3, 13.7, 14.1, 14.8 };
        auto [W1, p_value1] = shapiro_wilk_test(vec_data);
        gbassert(almost_equal(W1, 0.979, 0.001));
        gbassert(almost_equal(p_value1, 0.0005, 0.0001));

        std::array<double, 6> arr_data = { 12.9, 14.6, 15.3, 13.7, 14.1, 14.8 };
        auto [W2, p_value2] = shapiro_wilk_test(arr_data);
        gbassert(almost_equal(W2, 0.979, 0.001));
        gbassert(almost_equal(p_value2, 0.0005, 0.0001));

        // Using a transformed range (e.g., square all values)
        auto transformed_data = vec_data | std::views::transform([](double x) { return x * x; });
        auto [W3, p_value3] = shapiro_wilk_test(transformed_data);
        gbassert(almost_equal(W3, 0.985, 0.001));
        gbassert(almost_equal(p_value3, 0.0003, 0.0001));
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, student_test, std::launch::async)
    {
        // === Short Sample Test (n = 6) ===
        // Mean: 10 ± 0.148413
        //    Standard Deviation : 0.141421 ± 0.258576
        std::vector<double> short_data = { 10.1, 10.2, 9.9, 10.0, 9.8, 10.0 };

        student_t short_sample(short_data, 0.95);
        auto [mean_s, err_mean_s] = short_sample.mean_pair();
        auto [stddev_s, err_stddev_s] = short_sample.stddev_pair();
        gbassert(almost_equal(mean_s, 10.0, 0.01));
        gbassert(almost_equal(err_mean_s, 0.148413, 0.0001));
        gbassert(almost_equal(stddev_s, 0.141421, 0.0001));
        gbassert(almost_equal(err_stddev_s, 0.258576, 0.0001));

        //    === Long Sample Test(n = 100) ===
        //    Mean : 10 ± 0.0398843
        //    Standard Deviation : 0.201008 ± 0.0570195
        std::vector<double> long_data;
        for (int i = 0; i < 100; ++i) {
            double val = 10.0 + ((i % 2 == 0) ? 0.2 : -0.2);  // Small oscillating variation
            long_data.push_back(val);
        }

        student_t long_sample(long_data, 0.95);
        auto [mean_l, err_mean_l] = long_sample.mean_pair();
        auto [stddev_l, err_stddev_l] = long_sample.stddev_pair();
        gbassert(almost_equal(mean_l, 10.0, 0.01));
        gbassert(almost_equal(err_mean_l, 0.0398843, 0.0001));
        gbassert(almost_equal(stddev_l, 0.201008, 0.0001));
        gbassert(almost_equal(err_stddev_l, 0.0570195, 0.0001));
    }

    //--------------------------------------------------------------------------------------------
    namespace helpers
    {
        // Compute RMSE but skip the first N transient samples
        double compute_rmse(const std::vector<double>& ref,
            const std::vector<double>& test,
            std::size_t skip = 0)
        {
            if (ref.size() != test.size() || ref.size() <= skip)
                throw std::runtime_error("Size mismatch or skip too large in RMSE");

            double sum_sq = 0.0;
            std::size_t count = 0;

            for (std::size_t i = skip; i < ref.size(); ++i) {
                double err = ref[i] - test[i];
                sum_sq += err * err;
                ++count;
            }

            return std::sqrt(sum_sq / count);
        }

        template<typename T>
        T max_abs_err(const std::vector<T>& a, const std::vector<T>& b) {
            assert(a.size() == b.size());
            long double m = 0;
            for (std::size_t i = 0; i < a.size(); ++i) {
                long double d = std::fabs(static_cast<long double>(a[i]) - static_cast<long double>(b[i]));
                if (d > m) m = d;
            }
            return static_cast<T>(m);
        }

        // Chebyshev polynomial T_k(x) evaluation (recurrence)
        template<typename T>
        T cheb_T(unsigned k, T x) {
            if (k == 0) return T{ 1 };
            if (k == 1) return x;
            T Tkm1 = T{ 1 };
            T Tk = x;
            for (unsigned i = 2; i <= k; ++i) {
                T Tkp1 = T{ 2 } *x * Tk - Tkm1;
                Tkm1 = Tk;
                Tk = Tkp1;
            }
            return Tk;
        }

        // Build signal s[n] = sum_{k=0..deg} a_k * T_k(x_n), where x_n = 2*n/(N-1) - 1
        template<typename T>
        std::vector<T> build_cheb_signal(std::size_t N, const std::vector<T>& coeffs) {
            std::vector<T> out;
            out.resize(N);
            if (N == 1) {
                T x = T{ 0 };
                T s = T{ 0 };
                for (std::size_t k = 0; k < coeffs.size(); ++k) s += coeffs[k] * cheb_T<T>(static_cast<unsigned>(k), x);
                out[0] = s;
                return out;
            }
            for (std::size_t n = 0; n < N; ++n) {
                T x = (T{ 2 } *static_cast<T>(n) / static_cast<T>(N - 1)) - T{ 1 };
                long double s = 0;
                for (std::size_t k = 0; k < coeffs.size(); ++k) {
                    s += static_cast<long double>(coeffs[k]) * static_cast<long double>(cheb_T<T>(static_cast<unsigned>(k), x));
                }
                out[n] = static_cast<T>(s);
            }
            return out;
        }

        // Add Gaussian noise with given stddev
        template<typename T>
        std::vector<T> add_gaussian_noise(const std::vector<T>& signal, T stddev, std::mt19937& rng) {
            std::normal_distribution<double> d(0.0, static_cast<double>(stddev));
            std::vector<T> out(signal.size());
            for (std::size_t i = 0; i < signal.size(); ++i) out[i] = signal[i] + static_cast<T>(d(rng));
            return out;
        }

    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, chebyshev_test1, std::launch::async)
    {
        std::mt19937 rng(123456);
        using namespace helpers;
        const std::size_t N1 = 200;
        const unsigned deg1 = 5;
        std::vector<double> coeffs1(deg1 + 1);
        std::uniform_real_distribution<double> ud1(-1.0, 1.0);
        for (auto& c : coeffs1) 
            c = ud1(rng);

        auto clean1 = build_cheb_signal<double>(N1, coeffs1);
        auto filtered1 = cheb::chebyshev_filter(clean1, deg1);

        double maxerr1 = max_abs_err(clean1, filtered1);
        gbassert(maxerr1 <= 1e-8);
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, chebyshev_test2, std::launch::async)
    {
        std::mt19937 rng(123456);
        using namespace helpers;
        const std::size_t N2 = 512;
        const unsigned deg2 = 6;
        std::vector<double> coeffs2(deg2 + 1);
        std::uniform_real_distribution<double> ud2(-2.0, 2.0);
        for (auto& c : coeffs2) 
            c = ud2(rng);

        auto clean2 = build_cheb_signal<double>(N2, coeffs2);
        double mean2 = 0;
        for (auto v : clean2) mean2 += v;
        mean2 /= static_cast<double>(clean2.size());
        double var2 = 0;
        for (auto v : clean2) var2 += (v - mean2) * (v - mean2);
        var2 /= static_cast<double>(clean2.size());
        double sigma2 = std::sqrt(var2) * 0.5;
        auto noisy2 = add_gaussian_noise(clean2, sigma2, rng);

        auto filtered2 = cheb::chebyshev_filter(noisy2, deg2);

        // Skip first few samples (order * 3 is a good rule of thumb for IIR filters)
        std::size_t transient_skip = 12;

        double rmse_noisy2 = compute_rmse(clean2, noisy2, transient_skip);
        double rmse_filtered2 = compute_rmse(clean2, filtered2, transient_skip);
        gbassert(rmse_filtered2 < rmse_noisy2);
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, chebyshev_test3, std::launch::async)
    {
        using namespace helpers;
        constexpr std::size_t N3 = 51;
        constexpr unsigned deg3 = 3;
        std::array<float, N3> arr3{};
        std::vector<float> coeffs3 = { 1.0f, 0.4f, -0.25f, 0.1f };
        auto clean_vec3 = build_cheb_signal<float>(N3, coeffs3);
        for (std::size_t i = 0; i < N3; ++i) arr3[i] = clean_vec3[i];

        auto filtered_arr3 = cheb::chebyshev_filter(arr3, deg3);
        double maxerr3 = 0;
        for (std::size_t i = 0; i < N3; ++i) maxerr3 = std::max(maxerr3, std::fabs(static_cast<double>(filtered_arr3[i] - arr3[i])));
        const double tol3 = 1e-5;
        gbassert(maxerr3 <= tol3);
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, chebyshev_test4, std::launch::async)
    {
        // edge cases: N==0 and N==1
        // N == 0 (empty vector)
        std::vector<double> empty4;
        auto out_empty4 = cheb::chebyshev_filter(empty4, 3);
        gbassert(out_empty4.empty());

        // N == 1
        std::vector<double> single4 = { 42.0 };
        auto out_single4 = cheb::chebyshev_filter(single4, 5);
        gbassert(out_single4.size() == 1);
        gbassert(std::fabs(out_single4[0] - 42.0) < 1e-12);
    }

    //--------------------------------------------------------------------------------------------
    GB_TEST(algorithm, chebyshev_test5, std::launch::async)
    {
        // Degenerate-columns robustness
        using namespace helpers;
    
        const std::size_t N5 = 12;   // intentionally small, makes columns close to collinear for large degree
        const unsigned deg5 = 11;   // high degree relative to N increases chance of degenerate directions
        std::vector<double> coeffs5(deg5 + 1, 0.0);
        // make a simple signal with a couple of coefficients so the matrix A will have structure
        coeffs5[0] = 1.0;
        coeffs5[1] = 0.5;
        // create clean signal
        auto clean5 = build_cheb_signal<double>(N5, coeffs5);
        // add small noise
        std::mt19937 rng5(98765);
        auto noisy5 = add_gaussian_noise<double>(clean5, 1e-6, rng5);

        bool ok = true;
        try {
            auto filtered5 = cheb::chebyshev_filter(noisy5, deg5); // strength forces smoothing behavior
            // ensure outputs are finite (no nan / inf)
            for (double v : filtered5) {
                if (!std::isfinite(v)) { ok = false; break; }
            }
        }
        catch (...) {
            ok = false;
        }
        gbassert(ok);
    }
}
